# Deep learning-based time series forecasting

## Abstract

With the advancement of deep learning algorithms and the growing availability of computational power, deep learning-based forecasting methods have gained significant importance in the domain of time series forecasting. In the past decade, there has been a rapid rise in time series forecasting approaches. This paper comprehensively reviews the advancements in deep learning-based forecasting models spanning 2014 to 2024. We provide a comprehensive examination of the capabilities of these models in capturing correlations among time steps and time series variables. Additionally, we explore methods to enhance the efficiency of long-term time series forecasting and summarize the diverse loss functions employed in these models. Moreover, this study systematically evaluates the effectiveness of these approaches in both univariate and multivariate time series forecasting tasks across diverse domains. We comprehensively discuss the strengths and limitations of various algorithms from multiple perspectives, analyze their capacity to capture different types of time series information, including trend and season patterns, and compare methods for enhancing the computational efficiency of these models. Finally, we summarize the experimental results and discuss the future directions in time series forecasting. Codes and datasets are available at https://github.com/TCCofWANG/Deep-Learning-based-Time-Series-Forecasting.

随着深度学习算法的进步和计算能力的日益普及，基于深度学习的预测方法在时间序列预测领域中获得了显著的重要性。过去十年间，时间序列预测方法迅速崛起。本文全面回顾了从2014年至2024年间基于深度学习的预测模型的进展。我们对这些模型在捕捉时间步骤和时间序列变量之间相关性方面的能力进行了深入考察。此外，我们探索了提升长期时间序列预测效率的方法，并总结了这些模型中使用的各种损失函数。

本研究系统地评估了这些方法在不同领域中的单变量和多变量时间序列预测任务的有效性。我们从多个角度全面讨论了各种算法的优点和局限性，分析了它们捕捉不同类型时间序列信息（包括趋势和季节模式）的能力，并比较了提高这些模型计算效率的方法。最后，我们总结了实验结果，并讨论了时间序列预测领域的未来方向。

代码和数据集可以在https://github.com/TCCofWANG/Deep-Learning-based-Time-Series-Forecasting 获取。

## 1 Introduction

### 1.1 Objective

Time series forecasting plays a crucial role in numerous applications, such as energy consumption (Wu et al. 2021; Guo et al. 2023; Son and Van Cuong 2023; Dinh et al. 2023), transportation planning (Venkateshwari et al. 2023; Hu and Xiong 2023; Chen et al. 2023) and weather forecasting (Ma et al. 2023; Mung and Phyu 2023; Chen et al. 2023). In these practical application scenarios, forecasting future time series with the help of historical data is of great significance for long-term planning and early warning in related fields (Wang et
al. 2023; Miller et al. 2024). This process can be shown in Fig. 1. Therefore, this paper aims to explore deep learning-based time series forecasting models from multiple perspectives, offering a comprehensive evaluation of current mainstream models and encouraging readers
to consider future directions for development in this field.

时间序列预测在许多应用中扮演着关键角色，如能源消耗（吴等人，2021；郭等人，2023；Son和Van Cuong，2023；Dinh等人，2023）、交通规划（Venkateshwari等人，2023；Hu和Xiong，2023；陈等人，2023）以及天气预报（Ma等人，2023；Mung和Phyu，2023；陈等人，2023）。在这些实际应用场景中，借助历史数据预测未来时间序列对于相关领域的长期规划和早期预警具有重要意义（王等人，2023；Miller等人，2024）。这一过程可以如图1所示。因此，本文旨在从多个角度探讨基于深度学习的时间序列预测模型，提供对当前主流模型的全面评估，并鼓励读者考虑该领域的未来发展走向。

Next, we will summarize the existing methods from four main perspectives: time-step dependencies, correlations between temporal variables, the trade-off between expanding the model’s receptive field and reducing computational costs, and loss functions.

接下来，我们将从四个主要角度总结现有方法：时间步长依赖性、时间变量之间的相关性、扩展模型感受野与减少计算成本之间的权衡、以及损失函数。

Time series information usually consists of time-step dependencies and correlations between temporal variables (Parzen 1961; Lacasa et al. 2015; Hsieh 2004; Orang et al. 2023). Fully exploiting these two types of information plays a crucial role in improving the model’s capability. Traditional models like the autoregressive integrated moving average (ARIMA) (Zhang 2003; Ariyo et al. 2014; Contreras et al. 2003) rely on statistical properties to extract information. However, they often fall short in fully capturing the time-step dependencies within complex time series. This is because traditional models primarily focus on linear features, while real-time series data usually contains intricate nonlinear correlations. As a result, traditional models struggle to adequately leverage these dependencies. In recent years, with the development of algorithms related to deep lCR121earning and the improvement of computational power, deep learning-based methods have become increasingly crucial in time series forecasting. Autoencoder and Stacked Autoencoders (SAE) (Lv et al. 2014) are utilized to extract the time-step features of the time series and obtain the prediction results directly. (CNNs) (Gudelek et al. 2017; Markova 2022; Lu et al. 2020; Zhao et al. 2017; Liu et al. 2018; Hatami et al. 2018) are often used to extract time-series features in the short-term range because of their ability to aggregate time-step data in the receptive field. To capture a broader range of temporal dependencies, the Temporal Convolutional Network (TCN) (Bai et al. 2018) expands the receptive field of its convolutional kernel. Specifically, TCN introduces dilated causal convolutions to time-series forecasting tasks. In contrast, Recurrent Neural Networks (RNNs) (Shi et al. 2015; Dey and Salem 2017; Salinas et al. 2020; Hajirahimi and Khashei 2023; Lai et al. 2018) are specialized for temporal sequences and, theoretically, do not suffer from the limited receptive fields characteristic of CNNs. However, related studies have shown that the recurrent structure of RNNs can lead to issues such as vanishing gradient, limiting their ability to leverage long-term dependencies in time series. To address this, researchers have developed models like Long Short- Term Memory (LSTM) (Shi et al. 2015; Fischer and Krauss 2018; Zheng et al. 2017) and Gated Recurrent Units (GRU) (Dey and Salem 2017), which employ gating mechanisms to better capture long-term temporal correlations. Despite these advancements, LSTM and GRU models still face challenges, such as vanishing gradient (Pascanu et al. 2013; Noh 2021; Le and Zuidema 2016) and error accumulation during training (Tang et al. 2021; Fan et al. 2019; Liao et al. 20185), which are common in RNN architectures. The effectiveness (Hewamalage et al. 2021; Pavlov-Kagadejev et al. 2024) of RNN-based forecasting models declines with longer forecasting time steps.

时间序列信息通常包括时间步长依赖性和时间变量之间的相关性（Parzen 1961；Lacasa等人，2015；Hsieh 2004；Orang等人，2023）。充分挖掘这两种信息对于提升模型的能力至关重要。传统模型如自回归积分滑动平均模型（ARIMA）（Zhang 2003；Ariyo等人，2014；Contreras等人，2003）依赖统计特性来提取信息。然而，它们在捕捉复杂时间序列中的时间步长依赖性方面往往力不从心。这是因为传统模型主要关注线性特征，而实时序列数据通常包含复杂的非线性相关性。因此，传统模型难以充分利用这些依赖关系。

近年来，随着深度学习相关算法的发展和计算能力的提升，基于深度学习的方法在时间序列预测中变得越来越重要。自动编码器和堆叠自动编码器（SAE）（Lv等人，2014）被用来提取时间序列的时间步长特征并直接获得预测结果。（卷积神经网络）CNNs（Gudelek等人，2017；Markova 2022；Lu等人，2020；Zhao等人，2017；Liu等人，2018；Hatami等人，2018）常用于短期范围内的特征提取，因为它们能够在感受野内聚合时间步长的数据。为了捕捉更广泛的临时依赖关系，时间卷积网络（TCN）（Bai等人，2018）扩展了其卷积核的感受野。具体而言，TCN将膨胀因果卷积引入到时间序列预测任务中。

相比之下，循环神经网络（RNNs）（Shi等人，2015；Dey和Salem，2017；Salinas等人，2020；Hajirahimi和Khashei，2023；Lai等人，2018）专为时间序列设计，理论上不会受到CNN特有的有限感受野的限制。然而，相关研究表明，RNN的循环结构可能导致诸如梯度消失的问题，限制了其利用时间序列中长期依赖性的能力。为此，研究人员开发了如长短期记忆（LSTM）（Shi等人，2015；Fischer和Krauss，2018；Zheng等人，2017）和门控循环单元（GRU）（Dey和Salem，2017）等模型，采用门控机制以更好地捕捉长期时间相关性。尽管有了这些进步，LSTM和GRU模型仍然面临挑战，如梯度消失（Pascanu等人，2013；Noh 2021；Le和Zuidema 2016）和训练期间的误差累积（Tang等人，2021；Fan等人，2019；Liao等人，2018），这些问题在RNN架构中很常见。基于RNN的预测模型的有效性（Hewamalage等人，2021；Pavlov-Kagadejev等人，2024）随着预测时间步长的增长而下降。

Given the exceptional performance of Transformer models in both natural language processing (Vaswani et al. 2017; Devlin et al. 2018) and image processing (Dosovitskiy et al. 2020) domains, these models are now being introduced to time series forecasting (Wu et al. 2021; Li et al. 2019; Zhou et al. 2021). Compared with RNN-based models, Transformer based models adopt an encoder-decoder structure (Wang et al. 2022; Woo et al. 2022; Lee et al. 2024) and the attention mechanism (Liu et al. 2023; Niu et al. 2021; Young et al. 2022). It can dramatically alleviate the error accumulation (Li et al. 2019; Zhou et al. 2021) in longterm time-series forecasting tasks. However, the authors of DLinear (Yun et al. 2019) point out that the attention mechanism is permutation invariance. The Transformer model does not make good use of time series order information. To solve this problem, DLinear uses a linear layer to implement time series forecasting.

鉴于Transformer模型在自然语言处理（Vaswani等人，2017；Devlin等人，2018）和图像处理（Dosovitskiy等人，2020）领域的卓越表现，这些模型现在正被引入到时间序列预测中（Wu等人，2021；Li等人，2019；Zhou等人，2021）。与基于RNN的模型相比，基于Transformer的模型采用了编码器-解码器结构（Wang等人，2022；Woo等人，2022；Lee等人，2024）和注意力机制（Liu等人，2023；Niu等人，2021；Young等人，2022），这可以显著减轻长期时间序列预测任务中的误差累积（Li等人，2019；Zhou等人，2021）。

然而，DLinear（Yun等人，2019）的作者指出，注意力机制具有排列不变性，这意味着Transformer模型未能充分利用时间序列的顺序信息。为了解决这个问题，DLinear使用线性层来实现时间序列预测。

Generally speaking, the correlation between time steps in a time series comprises multiple patterns (Cleveland et al. 1990; Hyndman and Athanasopoulos 2018; Dagum 2010), including trend (Verbesselt et al. 2010) [62] (Qi and Zhang 2008; Woodward and Gray 1993), seasonal patterns (Bell and Hillmer 1984; De Livera et al. 2011), etc. To reduce the complexity of time series forecasting and capture these temporal patterns, some models have introduced time series decomposition techniques (Wu et al. 2021; Zhou et al. 2022; Oreshkin et al. 2019; Woo et al. 2022). These approaches initially decompose the time series into several components, usually containing trend information, seasonal information, time-scale information (Taylor and Letham 2018; Jiang et al. 2021; Murray et al. 2000), and other time-series information. Subsequently, the model analyzes these distinct elements using specialized modules. For instance, Autoformer (Wu et al. 2021) utilizes a mean filter to convolve the input sequence, extracting trend terms that represent the time series’ trend patterns. Similarly, Fedformer (Zhou et al. 2022) employs multiple mean filters of varying sizes to derive trend terms, effectively addressing the limited receptive field issue. LSTnet (Lai et al. 2018) employs linear mapping to extract trend information from sequences and incorporates a predefined window to minimize the impact of distant information on trend forecasting. N-BEATS (Oreshkin et al. 2019) adopts a polynomial fitting method to model the time series’ trend terms. Similarly, both DLinear (Yun et al. 2019) and TDformer (Zhang et al. 2022) utilize shallow linear layers for this purpose. For seasonal information, LSTnet introduces a skip-connection architecture based on LSTM, enabling the model to account for information from time steps preceding a fixed interval, thereby capturing seasonal information in the data. Autoformer enhances the ability of the attention mechanism to discern seasonal patterns by using time-delayed similarities of the input. Fedformer, on the other hand, transforms the input time series into the frequency domain and employs an attention mechanism to analyze similarities between frequency components, effectively capturing the periodicity of the time series. ETSformer (Woo et al. 2022) filters frequency components based on their magnitude, reducing noise interference in seasonal information capturing. Time-scale information (Zhai et al. 2023), referring to the correlation of time steps at different scales, is addressed by models like Scaleformer (Shabani et al. 2022) and Pyraformer (Liu et al. 2021). The former applies downsampling to acquire inputs at various temporal scales and uses a forecasting model for multi-scale predictions. The latter processes time series at different scales and employs an attention mechanism to derive cross-scale attention correlations.

一般来说，时间序列中时间步长之间的相关性包含多种模式（Cleveland等人，1990；Hyndman和Athanasopoulos，2018；Dagum，2010），包括趋势（Verbesselt等人，2010）[62]（Qi和Zhang，2008；Woodward和Gray，1993）、季节模式（Bell和Hillmer，1984；De Livera等人，2011）等。为了降低时间序列预测的复杂性并捕捉这些时间模式，一些模型引入了时间序列分解技术（Wu等人，2021；Zhou等人，2022；Oreshkin等人，2019；Woo等人，2022）。这些方法首先将时间序列分解为几个组成部分，通常包括趋势信息、季节信息、时间尺度信息（Taylor和Letham，2018；Jiang等人，2021；Murray等人，2000）及其他时间序列信息。然后，模型使用专门的模块分析这些不同的元素。

例如，Autoformer（Wu等人，2021）利用均值滤波器对输入序列进行卷积，提取代表时间序列趋势模式的趋势项。同样，Fedformer（Zhou等人，2022）采用不同大小的多个均值滤波器来得出趋势项，有效解决了感受野有限的问题。LSTnet（Lai等人，2018）通过线性映射从序列中提取趋势信息，并结合预定义窗口以最小化远处信息对趋势预测的影响。N-BEATS（Oreshkin等人，2019）采用多项式拟合方法建模时间序列的趋势项。同样，DLinear（Yun等人，2019）和TDformer（Zhang等人，2022）也使用浅层线性层来达到此目的。

对于季节信息，LSTnet基于LSTM引入跳连架构，使模型能够考虑固定间隔前的时间步骤信息，从而捕捉数据中的季节信息。Autoformer通过使用输入的时间延迟相似性增强了注意力机制识别季节模式的能力。另一方面，Fedformer将输入时间序列转换到频域，并使用注意力机制分析频率成分之间的相似性，有效捕捉时间序列的周期性。ETSformer（Woo等人，2022）根据其幅度过滤频率成分，减少了在捕捉季节信息时的噪声干扰。

时间尺度信息（Zhai等人，2023），指的是不同尺度上时间步长的相关性，由Scaleformer（Shabani等人，2022）和Pyraformer（Liu等人，2021）等模型解决。前者应用下采样获取不同时间尺度的输入，并使用预测模型进行多尺度预测。后者在不同尺度上处理时间序列，并使用注意力机制推导跨尺度的注意力相关性。

In addition to time-step dependencies, the essence of time series information also lies in the cross-time-step correlations among variables (Chakraborty et al. 1992; Yin et al. 2019). Thus, feature extraction of time series variables and exploring the inter-variable correlations are crucial for accurate forecasting. The TFT (Lim et al. 2021) employs RNN for feature extraction from time series variables and incorporates a feature filtering module to identify and utilize valuable information within these features. Aliformer (Qi et al. 2021) categorizes input time-series variables and incorporates future information about these variables, enhancing the model’s forecasting capabilities. Crossformer (Zhang and Yan 2022) leverages the attention mechanism to analyze attention-based correlations between variables, offering a nuanced approach to understanding their interplay. It is worth noting that in recent years, with the development of large language models(LLMS) (Zhao et al. 2023) like Chat- GPT (Achiam et al. 2023), LLMs can directly or indirectly generate prediction sequences through prompt engineering (Liang et al. 2024; Zhang et al. 2024).

除了时间步长依赖性之外，时间序列信息的本质还在于变量之间的跨时间步长相关性（Chakraborty等人，1992；Yin等人，2019）。因此，时间序列变量的特征提取和探索变量间的相关性对于准确预测至关重要。TFT（Lim等人，2021）使用RNN从时间序列变量中提取特征，并结合特征过滤模块以识别并利用这些特征中的有价值信息。Aliformer（Qi等人，2021）对输入的时间序列变量进行分类，并纳入关于这些变量的未来信息，从而增强模型的预测能力。Crossformer（Zhang和Yan，2022）利用注意力机制分析变量之间的基于注意力的相关性，提供了理解它们相互作用的细致方法。

值得注意的是，近年来，随着大型语言模型（LLMs）（如Chat-GPT（Achiam等人，2023））的发展（Zhao等人，2023），这些模型能够通过提示工程直接或间接生成预测序列（Liang等人，2024；Zhang等人，2024）。这表明大型语言模型在时间序列预测领域也展现出了潜在的应用前景。

CNN models are constrained by their limited receptive field, hindering their ability to effectively capture long-term time series data (Tang et al. 2020; Gál et al. 2004; Luo et al. 2016). The RNN model, due to the problems of error accumulation, vanishing gradient, and exploding gradient, also cannot handle the long-term time series prediction task well. While Transformer models circumvent these issues, the attention mechanism’s computational cost grows quadratically with the series length, rendering the traditional Transformer impractical for long-term forecasting (Li et al. 2019). Therefore, some research is devoted to reducing the computational cost of the attention mechanism, primarily through sparse attention mechanisms or shortening time series length. Related studies based on the sparse attention mechanism include: LogTrans (Li et al. 2019) filters the target of attention computation based on the distance between time steps, reducing computation. Reformer (Kitaev et al. 2020) maps the data into a hash space and filters the target of attention computation based on the distance among time steps in the hash space. Informer (Zhou et al. 2021) filters the target of attention computation based on computational output distribution. Related studies on reducing series length include: Informer utilizes convolutional aggregation of time steps in the receptive field. Convolutional aggregation reduces the input series length of the attention mechanism. PatchTST (Nie et al. 2022) slices long sequences into multiple fixed-size patches, reducing the attention mechanism’s computational cost.

CNN模型受限于其有限的感受野，这限制了它们有效捕捉长期时间序列数据的能力（Tang等人，2020；Gál等人，2004；Luo等人，2016）。由于误差累积、梯度消失和梯度爆炸问题，RNN模型也无法很好地处理长期时间序列预测任务。虽然Transformer模型避开了这些问题，但注意力机制的计算成本随着序列长度的增加而呈二次方增长，使得传统的Transformer在长期预测中不切实际（Li等人，2019）。因此，一些研究致力于降低注意力机制的计算成本，主要通过稀疏注意力机制或缩短时间序列长度来实现。

基于稀疏注意力机制的相关研究包括：LogTrans（Li等人，2019）根据时间步长之间的距离过滤注意力计算的目标，从而减少计算量。Reformer（Kitaev等人，2020）将数据映射到哈希空间，并基于哈希空间中时间步长之间的距离过滤注意力计算的目标。Informer（Zhou等人，2021）基于计算输出分布过滤注意力计算的目标。

关于减少序列长度的研究包括：Informer利用感受野内的时间步骤卷积聚合，卷积聚合减少了注意力机制的输入序列长度。PatchTST（Nie等人，2022）将长序列切割成多个固定大小的块，以此减少注意力机制的计算成本。这些方法为解决长期时间序列预测中的挑战提供了新的视角和解决方案。

Regarding loss function, the above deep learning-based models commonly use Mean Absolute Error (MAE) or Mean Squared Error (MSE) to evaluate the gap between predictions and actual outcomes (Li et al. 2019; Zhou et al. 2021; Kitaev et al. 2020; Zhou et al. 2022; Oreshkin et al. 2019). However, using MAE or MSE as the sole optimization objective has some limitations (Goodfellow et al. 2014; Mogren 2016; Lyu et al. 2019). In response, several models have innovated upon the traditional loss function to address this issue. For instance, DeepAR (Salinas et al. 2020) converts the model output from specific values to probability distributions, using negative log-likelihood as its loss function. Similarly, SSDNet (Lin et al. 2021) integrates negative log-likelihood with MAE to form a hybrid loss function, allowing for the assessment of discrepancies in both value and probability terms. AST (Wu et al. 2020) employs a strategy inspired by the training mechanism of generative adversarial networks (GANs) (Goodfellow et al. 2014), comprising both discriminant loss and generative loss components. This approach facilitates the alignment of the predicted distribution with the actual data distribution.

关于损失函数，上述基于深度学习的模型通常使用平均绝对误差（MAE）或均方误差（MSE）来评估预测值与实际结果之间的差距（Li等人，2019；Zhou等人，2021；Kitaev等人，2020；Zhou等人，2022；Oreshkin等人，2019）。然而，仅使用MAE或MSE作为优化目标存在一些局限性（Goodfellow等人，2014；Mogren 2016；Lyu等人，2019）。

为此，一些模型对传统损失函数进行了创新以解决这一问题。例如，DeepAR（Salinas等人，2020）将模型输出从具体数值转换为概率分布，并使用负对数似然作为其损失函数。同样，SSDNet（Lin等人，2021）将负对数似然与MAE结合形成混合损失函数，从而允许在数值和概率方面评估差异。AST（Wu等人，2020）采用了一种受生成对抗网络（GANs）训练机制启发的策略（Goodfellow等人，2014），包括判别损失和生成损失两部分。这种方法有助于使预测分布与实际数据分布相一致。这些改进使得模型在处理时间序列预测任务时更加灵活和准确。

Deep learning architectures usually require large-scale labeled datasets for achieving good performance on forecasting time series. Recent techniques of self-supervised learning (Pöppelbaum et al. 2022; Jaiswal et al. 2020) have opened up new a research frontier where deep learning architectures can learn general features from unlabeled time series. The task of self-supervised learning is usually accomplished with some sort of time-series augmentation such as flipping, random noise, time warping, and random smoothing. Based on these data augmentation methods (Wen et al. 2020; Cui 2016) and the strategy of contrastive training (Pöppelbaum et al. 2022; Al-Tahan and Mohsenzadeh 2021), deep learningbased time-series prediction models can capture temporal features during the pre-training phase. Subsequently, with a small amount of labeled data, they train the predictor to carry out predictions. At the same time, recent technology has also leveraged Few-Shot Learning to address the challenge of limited large-scale labeled datasets. This approach involves training the model on various public datasets, enabling it to extract time-series features effectively and exhibit strong generalization capabilities. Such a strategy leads to enhanced performance when applied to new datasets. Methods employing Few-Shot Learning can be categorized into two distinct directions. In Direction 1, the Memory network (Weston et al. 2014) approach is utilized. This involves encoding historical time-series data during training and retrieving these encodings when presented with new time-series datasets. This allows the model to identify similar patterns and make accurate predictions (Iwata and Kumagai 2020). Direction 2 involves using pre-trained LLMs known for their robust generalization abilities to generate precise predictions for time series data (Jin et al. 2023).

深度学习架构通常需要大规模标记数据集才能在时间序列预测上取得良好表现。最近的自监督学习技术（Pöppelbaum等人，2022；Jaiswal等人，2020）开辟了一个新的研究前沿，使得深度学习架构可以从无标记的时间序列中学习通用特征。自监督学习任务通常通过某种时间序列增强技术完成，如翻转、随机噪声添加、时间扭曲和随机平滑等。基于这些数据增强方法（Wen等人，2020；Cui 2016）和对比训练策略（Pöppelbaum等人，2022；Al-Tahan和Mohsenzadeh 2021），基于深度学习的时间序列预测模型能够在预训练阶段捕捉时间特征。随后，仅需少量标记数据即可训练预测器以进行预测。

与此同时，最近的技术也利用了少样本学习（Few-Shot Learning）来应对大规模标记数据集有限的挑战。这种方法包括在多个公共数据集上训练模型，使其能够有效地提取时间序列特征并展示出强大的泛化能力。当应用于新数据集时，这种策略能带来性能上的提升。采用少样本学习的方法可以分为两个不同的方向：

方向一：使用记忆网络（Weston等人，2014）的方法，这涉及到在训练过程中对历史时间序列数据进行编码，并在遇到新的时间序列数据集时检索这些编码。这允许模型识别相似模式并做出准确预测（Iwata和Kumagai 2020）。
方向二：利用以其强大的泛化能力著称的预训练大型语言模型（LLMs）对时间序列数据进行精确预测（Jin等人，2023）。这种方法展示了如何利用先进的自然语言处理技术解决时间序列分析中的问题。

